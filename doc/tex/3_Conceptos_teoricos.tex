\capitulo{3}{Conceptos teóricos}

En este capítulo se explicarán superficialmente los conceptos por los cuales se han desarrollado este proyecto, una explicación más completa de los modelos que se han usado se encuentran en la sección~\ref{cap:asp-rel}.

\subsection{Definiciones}

\textbf{Crisis epiléptica}~\cite{epilepsia}: se trata de un evento imprevisto de corta duración que comienza y termina de forma súbita. Se originan en el cerebro y pueden provocar convulsiones, rigidez, desvanecimiento o espasmos musculares según el foco de origen del mismo. Si la duración de la crisis fuese de más de cinco minutos se considera \textit{status epilepticus} (puede provocar daños neuronales y es improbable que paren por si solas) y se necesita atención médica inmediata para mitigar los efectos.

\textbf{Preprocesado}~\cite{ubu:mineria1}: proceso por el cual se realizan operaciones sobre los datos con el fin de facilitar la interpretación de los mismos. Engloba procesos como la eliminación de instancias ruidosas, suavizado de señales mediante filtros, normalización de las características, eliminación de aquellas que poseen una baja variabilidad, el análisis estadístico y la proyección de los datos en espacios de menor dimensionalidad para su visualización, etc.

\textbf{Análisis de componentes principales}~\cite{wiki:pca}: se trata de una técnica estadística que se utiliza para crear una descripción del conjunto de datos utilizando unas variables no correlacionadas. El objetivo es encontrar los ejes de máxima varianza y realizar proyecciones de menor dimensionalidad de los datos facilitando la interpretación de los datos.

\textbf{Proyección a 2-variedad} (\textit{Manifold learning}): se define como variedad a un objeto geométrico que representa un espacio que se parece localmente, la idea intuitiva sobre este concepto es el de un mapa, que proyecta en dos dimensiones un objeto que existe en tres dimensiones~\cite{wiki:manifold}. Por tanto, una proyección a 2-variedad es el proceso por el cual podemos disminuir la dimensionalidad de un conjunto de datos a dos dimensiones y poder estudiarlo mejor~\cite{tool:scikit-learn}. De la misma manera que no existe una única forma de transformar una esfera a un plano, tampoco existe una única forma de proyectar el conjunto de dimensiones a dos dimensiones, esto se explora en el capítulo 5 del Apéndice \textit{Cuaderno de investigación} adjuntado.

\textbf{Clasificador}: se trata de un algoritmo de aprendizaje supervisado que tiene de entrada los datos de una instancia y obtiene de salida la predicción de la clase a la que pertenece.

\textbf{Detección de anomalías}~\cite{wiki:ooc}: también conocido como clasificación de clase única (\textit{one-class clasification}), es un tipo de clasificador que se centra en acotar el espacio en el cual las instancias de una única clase existen de tal manera que detecte como anomalía cualquier instancia que no esté dentro de ese espacio.

\textbf{\textit{Ensemble}}~\cite{ubu:mineria3}: consiste en un método que se basa en la premisa que un conjunto de clasificadores débiles al combinarse genera un clasificador fuerte. Bajo esta definición se pueden crear diversas técnicas que permitan crear estos clasificadores. Algunas de estas técnicas son: crear subconjuntos aleatorios de las instancias para entrenar el mismo clasificador con diversos datos (\textit{bagging}); entrenar a los clasificadores con pesos diferentes para las instancias o remuestreando los datos según este criterio (\textit{boosting}); usar diferentes semillas para los clasificadores (comité aleatorio); creación de conjuntos de árboles de decisión según diferentes criterios (bosques).

\textbf{Conjunto de datos desequilibrados}: también conocidos como desbalanceados, trata de un conjunto de datos en el cual las clases no están igualmente representadas existiendo una gran desproporción. Esta diferencia puede ser, como ejemplo, con proporciones de un 1\% para la clase minoritaria y un 99\% para la mayoritaria. Esto provoca en clasificadores normales que las instancias de la clase minoritaria sean ignoradas ya que un de predecir siempre las instancias como clase mayoritaria el acierto sería muy alto (en el ejemplo anterior tendríamos una precisión del 99\%).

\textbf{Balanceo de datos}~\cite{diez2015random, diez2015diversity, galar2012review}: este es el proceso por el cual se pretende equilibrar la proporción entre las clases de un conjunto de datos desequilibrados. Estos métodos pueden ser de sobremuestreo creando nuevas instancias de la clase minoritaria a partir de los datos existentes, submuestreo eliminando instancias de la clase mayoritaria o el muestreo aleatorio creando un \textit{ensemble} utilizando diversos conjuntos balanceados de manera aleatoria.